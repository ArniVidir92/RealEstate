## Residuals
Begin by looking at the residuals from this model

```{r}
indexPlotJackResiduals(lm.all)
```

Here the blue line represent 2 standard deviation from 0 and green line 3 standard deviation away from 0. To help us identify the possible outliers we mark points 2 sd from 0 with their index.  We clearly see that there are some possible outliers that need further diagnostics.

## Leverages

The next thing to do is looking at the leverages, that is the measure of how far independent variable values of an observation are from those of the other observation.

```{r}
indexPlotLeverage(lm.all)
```


## Studentized residuals

Studentized residuals are sometimes preferred in residual plots as they have been standardized to have equal variance. They are also a big part in the Jackkiife residulas that follows

```{r}
stres <- indexPlotStResiduals(lm.all)+ylim(-5,20)
```

Blue and green line represent as before 2 and 3 sd from zero. 

```{r}
jackres <- indexPlotJackResiduals(lm.all)+ylim(-5,20)
```

```{r}
multiplot(stres,jackres,cols = 2)
```

Cook's distance (calculated w.r.t Jackknife and Std.Residuals) is a good way to diagnose influential points in the model. Points with high Cooks distance are affecting the model more than the others. The green points have high Cooks distance, but the blue points have high Cooks distance but also high leverage.

```{r}
indexPlotCookdistance(lm.all)
```

To see how well the model fits the data, we plot the fitted value against residuals. This should be scatterplot with no specified form.

```{r}
fittedVsresiduals(lm.all)
```

We clearly see this is not what we expected to see. This means we have to do some transformation and remove the biggest outliers.


```{r}
###################################### R squared adjusted fyrir lm.all
Radj.all <- CalculateRadjusted(lm.all, test) # 0.7990392
```


```{r}
#################################### lm.allNoOutliers Here I take out all outliers and get a new model #################
lm.allNoOutlier <- removeOutliersWStdResMoreThanThree(lm.all)
Radj.allNoOutliers <- CalculateRadjusted(lm.allNoOutlier, test) # 0.7328961
```


```{r}
#################################### lm.allNoInfluential Here I take out all influential points and get a new model ####
lm.allNoInfluential <- removeInfluential(lm.all,maxCookDistance = 4/n)
Radj.allNoInfluential <- CalculateRadjusted(lm.allNoInfluential, test) # 0.7327364
```


